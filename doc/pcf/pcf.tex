\documentclass[journal]{IEEEtran}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[colorlinks=true, linkcolor=black]{hyperref} % Links
\usepackage{makeidx} % Indexierung
\usepackage{siunitx}
%\usepackage[ngerman]{babel} % deutsche Sonderzeichen
\usepackage[utf8]{inputenc}
\usepackage{geometry} % Dokumentendesign wie Seiten- oder Zeilenabstand bestimmen
%\usepackage[toc,page]{appendix}

% Graphiken
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{pgfcore}
\usepackage{pgfopts}
\usepackage{pgfornament}
\usepackage{pgf}
\usepackage{ifthen}
\usepackage{booktabs}

% Tabellen
\usepackage{tabu}
\usepackage{longtable}
\usepackage{colortbl} % Tabellen faerben
\usepackage{multirow}
\usepackage{diagbox} % Tabellenzelle diagonal splitten

\usepackage{xcolor} % Farben
\usepackage[framemethod=tikz]{mdframed} % Hintergrunderstellung
\usepackage{enumitem} % Enumerate mit Buchstaben nummerierbar machen
\usepackage{pdfpages}
\usepackage{listings} % Source-Code darstellen
\usepackage{eurosym} % Eurosymbol
\usepackage[square,numbers]{natbib}
\usepackage{here} % figure an richtiger Stelle positionieren
\usepackage{verbatim} % Blockkommentare mit \begin{comment}...\end{comment}
\usepackage{ulem} % \sout{} (durchgestrichener Text)
\usepackage{abstract}
\usepackage{blindtext}

% BibLaTex
\bibliographystyle{acm}

% Aendern des Anhangnamens (Seite und Inhaltsverzeichnis)
%\renewcommand\appendixtocname{Anhang}
%\renewcommand\appendixpagename{Anhang}

% mdframed Style {{{
\mdfdefinestyle{codebox}{
	linewidth=2.5pt,
	linecolor=codebordercolor,
	backgroundcolor=codecolor,
	shadow=true,
	shadowcolor=black!40!white,
	fontcolor=black,
	everyline=true,
}
% }}}

% Seitenabstaende
%\geometry{left=15mm,right=15mm,top=15mm,bottom=20mm}

% TikZ Bibliotheken {{{
\usetikzlibrary{
    arrows,
    arrows.meta,
    decorations,
    backgrounds,
    positioning,
    fit,
    petri,
    shadows,
    datavisualization.formats.functions,
    calc,
    shapes,
    shapes.multipart
}
% }}}

\pgfplotsset{width=7cm,compat=1.15}

\definecolor{codecolor}{HTML}{EEEEEE}
\definecolor{codebordercolor}{HTML}{CCCCCC}

% Standardeinstellungen fuer Source-Code listings {{{
\lstset{
    language=C,
    breaklines=true,
    keepspaces=true,
    keywordstyle=\bfseries\color{green!70!black},
    basicstyle=\ttfamily\color{black},
    commentstyle=\itshape\color{purple},
    identifierstyle=\color{blue},
    stringstyle=\color{orange},
    showstringspaces=false,
    rulecolor=\color{black},
    tabsize=2,
    escapeinside={\%*}{*\%},
}
% }}}

%\input{libuml}
%\input{liberm}

\title{Partial Classification Forest}

\author{Jonas Fa{\ss}bender \\ [1ex]
  \href{mailto: jonas@fc-web.de}
  {jonas@fc-web.de}}
\date{}

\begin{document}

%\tableofcontents
%\newpage
%\listoffigures

\maketitle

\begin{abstract}
  %\noindent  \blindtext
\end{abstract}

\section{Introduction}

Some datasets do not allow a classifier to generate a
descision surface good enough to be able to predict unseen
observations well enough. Well, in this case, referrs to a
context dependent threshold for any quality measurement of
a classifier, for example the accuracy or an information
loss metric.

But for some of those problems, it may still be valuable
to predict only on partitions of the feature space, in
which the dataset is `clean' enough, meaning a classifier
can be found within the subset of the dataset laying inside
one of those partitions which equals or exceeds the
threshold.

This paper proposes a Monte Carlo based ensemble method
called Partial Classification Forest (PCF), builing an
ensemble of trees having a structure similar to
k-d trees to partition the feature space of the dataset in
order to find `clean' partitions. In the following a
tree generated by the PCF is spelled Tree with a capital
T, rather than tree, which is used to denote the data
structure.

In Section \MakeUppercase{\romannumeral 2} I will lay out
the structure of a Tree generated by the PCF before, in
Section \MakeUppercase{\romannumeral 3}, describing how
PCF uses the Trees and listing its parameters. After that I
will continue displaying test results using PCF\@. In
Section \MakeUppercase{\romannumeral 5} I will discuss
further optimizations and possible additional features
before finishing with a conclusion.

\section{The Tree structure}

A Tree generated by the PCF is a binary search tree
structure similar to k-d trees. Its purpose is to randomly
generate disjoint partitions of a feature space.

It provides two operations, FIT, described with pseudo-code
in Algorithm 1, building the Tree based on a provided
dataset and the PREDICT operation (cmp. Algorithm 2),
returning a label for an observation.

It has two types of nodes, non-leaf nodes, here denoted as
Nodes and leaf nodes denoted as Leafs. The Node structure
contains three properties, a split value, a left and a
right successor, referencing either another Node or a
Leaf.

A Leaf, on the other hand, is the structure
representing a partition of the feature space, having a
label and two vectors with arbitrary
length containing the datapoints of a dataset laying inside
the partition.

% TODO: find paper on k-d trees
% picuture of a 2d dataset scatter plot (matplotlib) with
% lines and a graph of the tree
%
% after the picture describe the fitting and predicting of
% of the Tree

% 4: tests
% 5: discussion
% 6: conclusion

%For some datasets the quality of the data is not high
%enough to find a classifier

%!!! https://www.kaggle.com/zynicide/wine-reviews

%Notes: - compare workflow against anomaly detection
%         (outlier removal) + classifier vs. PCF
%
%       - find real datasets for testing (3?)
%
%       - read IF and other papers describing algorithms
%
%       - read How to write a good Scientific Paper


%\section{Partial Classification Forest}

%\section{Partial Classification using PCF}

%\section{Comparison to Anomaly Detection Algorithms}

%\section{Discussion}

%\section{Conclusion}

\end{document}
