\section{Tests}
\label{sec:tests}

This Section will present two conducted tests. It should
be noted here that, like described in the Introduction,
these are not very comprehensive tests. This Section rather
visualizes the use of the PCF predicting on partitions of
otherwise unpredictable datasets.

The first test will visualize what the descision surface of
the PCF looks like, the second will show how the PCF
behaves with different amounts of Trees.

Both tests are performed on a randomly generated,
normalized, two dimensional and binary labeled dataset. The
dataset contains five thousand observations and was
designed to be unpredictable, when predicted as a whole.
The plane from which the observations are generated
contains five partitions in which the observations all have
the same label. Observations from those five partitions
make up twenty percent of all observations and are the only
ones which should be predicted, because all points not
inside those partitions are labeled randomly. The optimal
descision surface would be equal to the area of the five
partitions.

All observations are generated by a pseudo-random number
generator\cite[chapter 9.6]{python}, therefore, every point
on the plane has the same probability to be chosen as an
observation for the dataset.

It is common practise in machine learning to split a
dataset into a training and a test set in order to find
the best model.\cite[chapter 18]{ki}
This approach is also used for the PCF. The training set is
used as the parameters $X$ and $y$ of FIT (Algorithm~%
\ref{alg:pcf_fit}) while PREDICT (Algorithm~%
\ref{alg:pcf_pred}) is used on every observation of the
test set.

Two metrics are used to describe the behaviour of the PCF,
(\romannumeral 1) $predicted$ and (\romannumeral 2)
$accuracy$. Both metrics are derived from comparing the
label of an observation returned by PREDICT with its actual
label from the dataset.

$Predicted$ is the percentage of predicted observations,
while $accuracy$ is the percentage of correctly classified
observartions from the test set.

For both tests $\gamma$, $\tau_l$ and $\tau_h$ are the
same. $\gamma$ and $\tau_l$ are equal to the values used in
Figure~\ref{fig:fit_example} while $\tau_h = 32$. The
dataset was splitted into a training and a test set such
that ten percent of the observations were used as the test
set.\footnote{For splitting scikit-learn's
  model\_selection.train\_test\_split was used during the
  tests.\cite{sklearn_api}} The observations were chosen
randomly.

The first test will show the descision surface of the PCF
with different $N$ and $\tau_{|X|}$. For the test three
different values, two, five and ten were used for both $N$
and $\tau_{|X|}$ to show how those two parameters change
the descision surface of the PCF. The test shows that for
$\tau_{|X|} = 2$ the PCF overfitted the data, which means
that $predicted$ exceeded twenty percent, the amount of
accurate observations while also failing to meet an
$accuracy$ equal to $\tau_l$. This results in the chaotic
descision surfaces shown in Figures~\ref{fig:x2_n2} -
\ref{fig:x2_n10}. On the other hand for $\tau{|X|} = 10$
the descision surface is very small which means the PCF's
$predicted$ is less than twenty percent (Figures~%
\ref{fig:x10_n2} - \ref{fig:x10_n10}).

The second test shows the influence the amount of Trees $N$
has on $predicted$ and $accuracy$. In this test
$\tau_{|X|}$ equals four.

Figure~\ref{fig:n} shows that, for this dataset with the
chosen thresholds, the PCF instances with $N < 30$ variate,
both their $predicted$ and $accuracy$ values. Is $30 \leq N
\leq 100$ $accuracy$ is constant and equals $\tau_l$.
$Predicted$ on the other hand, still rises in this
interval. Is $N \geq 100$ $predicted$ is higher than
$predicted$ with $N = 100$ and constant, but $accuracy$
fails to meet $\tau_l$, which means the PCF instances are
overfitting.

Furthermore the second test relates $predicted$ and
$accuracy$ of the observations from the test set to the
values for the training set, showing that more training
observations are predictable than test observations
(cmp. Figure~\ref{fig:n}).

\input{tests/descision_surface}

\input{tests/n_estimators}
