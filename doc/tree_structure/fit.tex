\subsection{The FIT operation}
\label{subsec:fit}

The FIT operation constructs a Tree, based on a dataset
split in observations ($X$) and their labels ($y$).
Algorithm~\ref{alg:fit} shows how FIT recursively builds a
Tree, which is at the beginning a pointer to a Nil node.

The most important parameter passed to FIT is $\gamma$.
$\gamma$ is a function returning (\romannumeral 1) a
predictor and (\romannumeral 2) the loss of it. Otherwise
$\gamma$ is treated as a black box by the PCF, so what the
predictor is and how its loss is calculated are not
relevant to the PCF, as long as the predictor is callable
and returns an element from the label set when called
(Algorithm~\ref{alg:pred}, line 9). The loss returned
by $\gamma$ gets compared to the quality threshold
$\tau_l$. Is the loss $\leq \tau_l$ the predictor is good
enough and $\Theta$ is transformed to an active Leaf
(Algorithm~\ref{alg:fit}, lines 2, 3).

There are two other thresholds besides $\tau_l$,
$\tau_{|X|}$, $\tau_h$. Both regulate the behaviour of a
Tree's growth. $\tau_{|X|}$ defines a minimum amount of
observations a Leaf must contain. One can easily imagine,
without $\tau_{|X|}$ or $\tau_{|X|} = 0$ a Tree would
never stop growing, since FIT would continue to split empty
partitions, trying to find a smaller partition which would
be predictable, even though no predictor could be
generated without observations to train it on.

$\tau_h$ further regulates the maximum path length of a
Tree. It is necessary besides $\tau_{|X|}$, because of the
following scenario: be $\tau_{|X|} = 2$ and there are two
equal observations in the dataset, but both having a
different label than the other one. Now $\gamma$, passed
$X$ containing only those two identical observations,
returns a predictor with a loss $> \tau_l$. Since $|X|$ is
still not smaller than $\tau_{|X|}$ FIT would continue
trying to separate the two inseperable observations. To
prevent such a szenario $\tau_h$ tells FIT to stop before
the Tree's height, the amount of edges of the longest path,
would exceed $\tau_h$. The path length of the Tree's root
to $\Theta$ is passed as a parameter $h$ to FIT.

Now, if neither $\tau_l$ is exceeded nor $\tau_{|X|}$ or
$\tau_h$ is violated, FIT performs a split and transforms
$\Theta$ to a Node (Algorithm~\ref{alg:fit}, lines 7ff).
The dimension the split is performed on is chosen in a
cyclic manner, a practise also applied to k-d trees
(Algorithm~\ref{alg:fit}, line 7).%
~\cite{Brown2015kdtree}
But rather than chosing the splitting value at the median
of the observations in the dimension, which is done in
order to construct balanced k-d trees, the splitting value
is random.\cite{Brown2015kdtree}

In order to chose a proper splitting value $\beta_X$ is
passed as another parameter to FIT. $\beta_X$ represents
the boundries for every dimension of the feature space
based on $X$. For each dimension $\beta_X$ contains a
tuple with the minimum and maximum value in the dimension
of all observations in $X$.

$\beta_X[\text{dimension}]$ is passed to a pseudo-random
number generator generating a random value so that
$lower(\beta_X[\text{dimension}]) \leq \text{random number}
\leq upper(\beta_X[\text{dimension}])$
(Algorithm~\ref{alg:fit}, line 8).

Afterwards $X$, $y$, $\beta_X$ are splitted into two new
disjoint partitions and FIT is recursively applied to the
two new partitions (Algorithm~\ref{alg:fit}, lines 10ff).

Since $\tau_h$ is defined, the maximum amount of nodes a
Tree can have is $2^{\tau_h + 1} - 1$\cite[chapter 16.1]%
{Teschl}, if the Tree would be perfectly balanced. For each
node FIT is called, so building a Tree has a worst case
time complexity of $\mathcal{O}((2^{\tau_h + 1} -1)*
\mathcal{O}(\text{FIT}))$. $\mathcal{O}(\text{FIT})$ is
determined by the size of $X$, since $X$ has to be splitted
and by $\mathcal{O}(\gamma)$. That said, a single FIT
operation would have a worst case time complexity of
$\mathcal{O}(|X| + \mathcal{O}(\gamma))$, which would mean
the time complexity of the whole fitting process would be
$\mathcal{O}((2^{\tau_h + 1} - 1) * (|X| + \mathcal{O}
(\gamma)))$.

% {{{
\begin{algorithm}
  \caption{: FIT($\Theta, X, y, h, \beta_X, \gamma,
    \tau_{l}, \tau_{|X|}, \tau_{h}$)}%
  \label{alg:fit}
  A Tree's FIT operation.

  Inputs:

    \begin{tabu}{llX}
    $\Theta$ &$-$ &a pointer to a Nil node; initially
      pointing to the root node of an empty Tree,\\
    $X$ &$-$ &input data,\\
    $y$ &$-$ &labels of X,\\
    $h$ &$-$ &height of the Tree; initially $h = 0$,\\
    $\beta_X$ &$-$ &lower and upper boundries of every
      dimension of X,\\
    $\gamma$ &$-$ &function returning a predictor and its
      loss,\\
    $\tau_{l}$ &$-$ &loss threshold,\\
    $\tau_{|X|}$ &$-$ &threshold for the size of X,\\
    $\tau_{h}$ &$-$ &height limit of the Tree
    \end{tabu}

  Output: void

  \noindent\rule{\linewidth}{0.4pt}

  \begin{algorithmic}[1]
    \STATE predictor, loss $\leftarrow \gamma(X, y)$
    \IF{loss $\leq \tau_{l}$}
      \STATE $\Theta \leftarrow$ LEAF(\TRUE, predictor,
         $X$, $y$)
    \ELSIF{$h > \tau_{h}$ \OR $|X| < \tau_{|X|}$ \OR
        loss $> \tau_{l}$}
      \STATE $\Theta \leftarrow$ LEAF(\FALSE, predictor,
        $X$, $y$)
    \ELSE
      \STATE dimension $\leftarrow h$ mod $|X[0]|$
      \STATE split $\leftarrow$ RANDOM($\beta_X[$dimension
        $]$)
      \STATE $\Theta \leftarrow$ NODE(split, NIL, NIL)
      \STATE split $X$, $y$ and $\beta_X$ into
        $X'$, $X''$, $y'$, $y''$, $\beta_X'$, $\beta_X''$
      \STATE FIT($\Theta$.left, $X'$, $y'$, $h + 1$,
        $\beta_X'$, \dots)
      \STATE FIT($\Theta$.right, $X''$, $y''$, $h + 1$,
        $\beta_X''$, \dots)
    \ENDIF
  \end{algorithmic}
\end{algorithm}
% }}}

\begin{figure*}
  \begin{subfigure}[b]{\textwidth}
    \centering
    \input{tree_structure/example_data}
    \caption{Scatterplot showing the observations and the
      splits done by the FIT operation.}
    \label{fig:scatter_example}
  \end{subfigure}
  \begin{subfigure}[b]{\textwidth}
    \centering
    \scalebox{0.9}{\input{tree_structure/example_tree}}
    \caption{The structure of the Tree generated by FIT.}
    \label{fig:tree_example}
  \end{subfigure}
  \caption{Example of FIT on a dataset seen in Figure
    \ref{fig:scatter_example}. $\gamma$ simply computes the
      probability of each label in $y$ and returns a
      function returning the label with the
      maximum probability and as loss 1 - the maximum
      probability. The thresholds are: $\tau_l = 1$,
      $\tau_{|X|} = 2$. $\tau_h$ can be any integer above
      2.
    }
\end{figure*}

